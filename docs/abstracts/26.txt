Title: Improved 6 dof Pose Estimation Using Post-Processing Validation

Industrial automation fully depends on the automatic pick-and-place of objects by a robot. For a robot to successfully grasp an object, it is essential to  identify it's 6 dof pose, and failure to do so accurately can cause the entire system to fail. While much research effort has been devoted to address this problem, accurate 6 dof object localization can still fail, especially when there exists noise, occlusion, and clutter in the scene. 
To address the problem of accurate 6 dof object pose estimation, we designed a novel deep neural network architecture called ValidNet which can identify incorrect poses returned by a pose estimation technique. Our network evaluates the aligned input scene and model (i.e. the object we want to grasp) using the pose predicted by the pose estimator. ValidNet takes raw unordered point clouds as input, extracts the features of the model and aligned scene, and measures their similarity in the high dimensional feature space. For feature extraction, we used the PointNet segmentation network, following which we applied point-wise correlation and max-pool operation to measure similarities in feature space. A fully connected layer was then employed to measure the similarities and provide a decision of pose estimation validity. 
To further improve the performance of ValidNet, we also explored the possibilities of fusing multiple input streams from different data modalities. We designed another architecture called multi-stream ValidNet where we used two different input streams (3D point clouds, and depth images). The point cloud stream is exactly as in ValidNet. In the depth stream, we used aligned depth images of the model and the scene. We used two feature extractor blocks for extracting features from the model and the scene images independently. These features can characterize the model and segment orientations. After that, we used a combined feature extractor block for accumulating the required information from the extracted features. Both feature extractor and combined feature extractor blocks consist of 2D CNN and max pool layers. After feature extraction, we used fully connected layers for the final classification.
We fused both streams by averaging the final scores. By combining the two streams, we are able to outperform our single-stream ValidNet and improve the current state-of-the-art pose estimation using Op-Net results by 6.06% on average on the Sil—êane dataset, improving the True Positive rate from 86.17% to 92.23%.

Publication Status of the Work: Unpublished (i.e., new work)

Link to Full Paper (if available): https://iopscience.iop.org/article/10.1088/2050-6120/ab716a

